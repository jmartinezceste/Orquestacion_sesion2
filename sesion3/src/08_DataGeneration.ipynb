{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32937f63-61a6-4251-a72f-caa8093a7d54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 01-DataGeneration\n",
    "Within this notebook, generate the following dataset:\n",
    "\n",
    "1. The user bronze table, \n",
    "2. The product bronze table, \n",
    "3. The daily transaction table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45af006a-7343-4197-97b9-dca681855135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The Highlevel Overview of the Data Dictionary\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/product/lhm/lhm_data.png\" width=\"600px\" style=\"float:right\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ad5aa4a-95da-4618-88d8-2d14707edfd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "## Configuration file\n",
       "\n",
       "Please change your catalog and schema here to run the demo on a different catalog.\n",
       "\n",
       "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
       "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=DBSQL&org_id=1330931038747594&notebook=%2Fconfig&demo_name=lakehouse-monitoring&event=VIEW&path=%2F_dbdemos%2FDBSQL%2Flakehouse-monitoring%2Fconfig&version=1\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "### License\n",
       "This demo installs the following external libraries on top of DBR(ML):\n",
       "\n",
       "\n",
       "| Library | License |\n",
       "|---------|---------|\n",
       "| faker      | [MIT](https://faker.readthedocs.io/en/master/)     |\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./08_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baae407d-4cc9-4497-9948-6122bea6c46f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./08_monitoring_00-global-setup-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "562bdbdc-3c87-478d-9a13-eaef7c6eb370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DBDemos.setup_schema(catalog, db, reset_all_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5da4567a-58a5-43bf-b5c8-1684967b9326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_exists = spark.catalog.tableExists('gold_user_purchase') and spark.catalog.tableExists('bronze_product') and spark.catalog.tableExists('bronze_user') and spark.catalog.tableExists('bronze_transaction') and spark.catalog.tableExists('gold_payment_method') \n",
    "\n",
    "if data_exists:\n",
    "  print(f'data alread existing in {catalog}.{dbName}. Please drop the schema to re-create them from scratch.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19b9e026-5786-4785-bb98-d2204505db60",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install the required library"
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1932564-0a69-4e49-8adf-54561fb67b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Genearate the user table\n",
    "\n",
    "Schema for the User Table:\n",
    "- **UserID**: Unique identifier for the user\n",
    "- **Username**: User's chosen display name\n",
    "- **Email**: User's email address\n",
    "- **PasswordHash**: Hashed version of the user's password\n",
    "- **FullName**: User's full name\n",
    "- **DateOfBirth**: User's date of birth\n",
    "- **Gender**: User's gender\n",
    "- **PhoneNumber**: User's contact number\n",
    "- **Address**: User's primary address\n",
    "- **City**: User's city of residence\n",
    "- **State**: User's state of residence\n",
    "- **Country**: User's country of residence\n",
    "- **PostalCode**: User's postal code\n",
    "- **RegistrationDate**: Date when the user registered on the platform\n",
    "- **LastLoginDate**: Date and time of the user's last login\n",
    "- **AccountStatus**: Status of the user's account (e.g., active, suspended)\n",
    "- **UserRole**: Role of the user (e.g., customer, admin)\n",
    "- **PreferredPaymentMethod**: User's preferred payment method\n",
    "- **TotalPurchaseAmount**: Total amount spent by the user\n",
    "- **NewsletterSubscription**: Whether the user is subscribed to the newsletter (yes/no)\n",
    "- **Wishlist**: List of product IDs in the user's wishlist\n",
    "- **CartItems**: List of product IDs currently in the user's cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f24cf84-70a4-4656-8964-d079b05fe700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    import pandas as pd\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "    from faker import Faker\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType, BooleanType, ArrayType, IntegerType, TimestampType, DoubleType\n",
    "\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # Function to generate user data\n",
    "    def generate_user_data(num_rows=10000):\n",
    "        user_data = []\n",
    "        \n",
    "        for _ in range(num_rows):\n",
    "            user = {\n",
    "                \"UserID\": fake.uuid4(),\n",
    "                \"Username\": fake.user_name(),\n",
    "                \"Email\": fake.email(),\n",
    "                \"PasswordHash\": fake.sha256(),\n",
    "                \"FullName\": fake.name(),\n",
    "                \"DateOfBirth\": fake.date_of_birth(minimum_age=18, maximum_age=90),\n",
    "                \"Gender\": random.choice([\"Male\", \"Female\", \"Other\"]),\n",
    "                \"PhoneNumber\": fake.phone_number(),\n",
    "                \"Address\": fake.address(),\n",
    "                \"City\": fake.city(),\n",
    "                \"State\": fake.state(),\n",
    "                \"Country\": fake.country(),\n",
    "                \"PostalCode\": fake.postcode(),\n",
    "                \"RegistrationDate\": fake.date_this_decade(),\n",
    "                \"LastLoginDate\": fake.date_time_between(start_date=\"-1y\", end_date=\"now\"),\n",
    "                \"AccountStatus\": random.choice([\"Active\", \"Suspended\", \"Inactive\"]),\n",
    "                \"UserRole\": random.choice([\"Customer\", \"Admin\"]),\n",
    "                \"PreferredPaymentMethod\": random.choice([\"Credit Card\", \"Debit Card\", \"PayPal\", \"Bank Transfer\"]),\n",
    "                \"TotalPurchaseAmount\": round(random.uniform(0, 10000), 2),\n",
    "                \"NewsletterSubscription\": random.choice([True, False]),\n",
    "                \"Wishlist\": [fake.uuid4() for _ in range(random.randint(0, 10))],\n",
    "                \"CartItems\": [fake.uuid4() for _ in range(random.randint(0, 5))]\n",
    "            }\n",
    "            user_data.append(user)\n",
    "        \n",
    "        return pd.DataFrame(user_data)\n",
    "\n",
    "    # Generate the user data\n",
    "    user_pdf = generate_user_data(10000)\n",
    "\n",
    "    # Convert the Pandas DataFrame to a PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"UserID\", StringType(), False),\n",
    "        StructField(\"Username\", StringType(), False),\n",
    "        StructField(\"Email\", StringType(), False),\n",
    "        StructField(\"PasswordHash\", StringType(), False),\n",
    "        StructField(\"FullName\", StringType(), False),\n",
    "        StructField(\"DateOfBirth\", DateType(), False),\n",
    "        StructField(\"Gender\", StringType(), False),\n",
    "        StructField(\"PhoneNumber\", StringType(), False),\n",
    "        StructField(\"Address\", StringType(), False),\n",
    "        StructField(\"City\", StringType(), False),\n",
    "        StructField(\"State\", StringType(), False),\n",
    "        StructField(\"Country\", StringType(), False),\n",
    "        StructField(\"PostalCode\", StringType(), False),\n",
    "        StructField(\"RegistrationDate\", DateType(), False),\n",
    "        StructField(\"LastLoginDate\", DateType(), False),\n",
    "        StructField(\"AccountStatus\", StringType(), False),\n",
    "        StructField(\"UserRole\", StringType(), False),\n",
    "        StructField(\"PreferredPaymentMethod\", StringType(), False),\n",
    "        StructField(\"TotalPurchaseAmount\", FloatType(), False),\n",
    "        StructField(\"NewsletterSubscription\", BooleanType(), False),\n",
    "        StructField(\"Wishlist\", ArrayType(StringType()), False),\n",
    "        StructField(\"CartItems\", ArrayType(StringType()), False)\n",
    "    ])\n",
    "\n",
    "    # Create Spark DataFrame and Write to Delta\n",
    "    user_df = spark.createDataFrame(user_pdf, schema)\n",
    "\n",
    "    # Write the Spark DataFrame to Delta format\n",
    "    user_df.write.mode('overwrite').saveAsTable('bronze_user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4716aab-5f62-4a45-89c9-ac48383a8490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Genearate the product table\n",
    "\n",
    "Schema for the Product Table:\n",
    "- **ProductID**: Unique identifier for the product\n",
    "- **ProductName**: Name of the product\n",
    "- **Category**: Category to which the product belongs\n",
    "- **SubCategory**: Subcategory of the product\n",
    "- **Brand**: Brand of the product\n",
    "- **Description**: Detailed description of the product\n",
    "- **Price**: Price of the product\n",
    "- **Discount**: Discount on the product (if any)\n",
    "- **StockQuantity**: Number of items available in stock\n",
    "- **SKU**: Stock Keeping Unit identifier\n",
    "- **ProductImageURL**: URL of the product image\n",
    "- **ProductRating**: Average rating of the product\n",
    "- **NumberOfReviews**: Number of reviews for the product\n",
    "- **SupplierID**: Unique identifier for the supplier\n",
    "- **DateAdded**: Date when the product was added to the inventory\n",
    "- **Dimensions**: Dimensions of the product (L x W x H)\n",
    "- **Weight**: Weight of the product\n",
    "- **Color**: Color of the product\n",
    "- **Material**: Material of the product\n",
    "- **WarrantyPeriod**: Warranty period of the product\n",
    "- **ReturnPolicy**: Return policy for the product\n",
    "- **ShippingCost**: Cost of shipping the product\n",
    "- **ProductTags**: Tags associated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94b411e5-c01f-41e3-8635-4cf3e0c822cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    import random\n",
    "\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # Expanded list of realistic product names related to categories\n",
    "    product_names = {\n",
    "        \"Electronics\": [\n",
    "            \"Smartphone\", \"Laptop\", \"Tablet\", \"Desktop Computer\", \"Camera\", \"Headphones\", \"Speakers\", \"Smartwatch\",\n",
    "            \"Fitness Tracker\", \"Bluetooth Earbuds\", \"Gaming Console\", \"Television\"\n",
    "        ],\n",
    "        \"Clothing\": [\n",
    "            \"Running Shoes\", \"Hiking Boots\", \"Sneakers\", \"Sandals\", \"Slippers\", \"Formal Shoes\", \"Wrist Watch\",\n",
    "            \"Sunglasses\", \"Handbag\", \"Backpack\", \"T-Shirt\", \"Sweater\", \"Jacket\", \"Jeans\", \"Dress\", \"Skirt\", \"Shorts\",\n",
    "            \"Swimwear\", \"Hat\", \"Scarf\"\n",
    "        ],\n",
    "        \"Home & Kitchen\": [\n",
    "            \"Vacuum Cleaner\", \"Blender\", \"Microwave Oven\", \"Refrigerator\", \"Air Conditioner\", \"Heater\", \"Fan\",\n",
    "            \"Electric Kettle\", \"Coffee Maker\", \"Toaster\", \"Cookware Set\", \"Knife Set\", \"Cutting Board\"\n",
    "        ],\n",
    "        \"Books\": [\n",
    "            \"Cookbook\", \"Novel\", \"Textbook\", \"Journal\", \"Notebook\", \"Children's Book\"\n",
    "        ],\n",
    "        \"Toys\": [\n",
    "            \"Puzzle\", \"Board Game\", \"Action Figure\", \"Doll\", \"Toy Car\", \"Building Blocks\"\n",
    "        ],\n",
    "        \"Sports\": [\n",
    "            \"Bicycle\", \"Treadmill\", \"Dumbbells\", \"Yoga Mat\", \"Protein Powder\"\n",
    "        ],\n",
    "        \"Health & Beauty\": [\n",
    "            \"Skincare Set\", \"Shampoo\", \"Conditioner\", \"Hair Dryer\", \"Electric Toothbrush\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    subcategories = {\n",
    "        \"Electronics\": [\"Smartphones\", \"Laptops\", \"Cameras\", \"Headphones\", \"Speakers\"],\n",
    "        \"Clothing\": [\"Men\", \"Women\", \"Kids\", \"Accessories\", \"Footwear\"],\n",
    "        \"Home & Kitchen\": [\"Appliances\", \"Cookware\", \"Furniture\", \"Decor\", \"Bedding\"],\n",
    "        \"Books\": [\"Fiction\", \"Non-Fiction\", \"Children's Books\", \"Educational\", \"Mystery\"],\n",
    "        \"Toys\": [\"Educational Toys\", \"Action Figures\", \"Board Games\", \"Dolls\", \"Puzzles\"],\n",
    "        \"Sports\": [\"Fitness Equipment\", \"Outdoor Gear\", \"Team Sports\", \"Individual Sports\", \"Sportswear\"],\n",
    "        \"Health & Beauty\": [\"Skincare\", \"Makeup\", \"Supplements\", \"Haircare\", \"Personal Care\"]\n",
    "    }\n",
    "\n",
    "    # Expanded list of realistic brand names\n",
    "    brands = [\n",
    "        \"BrandA\", \"BrandB\", \"BrandC\", \"BrandD\", \"BrandE\", \"BrandF\", \"BrandG\", \"BrandH\", \"BrandI\", \"BrandJ\",\n",
    "        \"BrandK\", \"BrandL\", \"BrandM\", \"BrandN\", \"BrandO\", \"BrandP\", \"BrandQ\", \"BrandR\", \"BrandS\", \"BrandT\",\n",
    "        \"BrandU\", \"BrandV\", \"BrandW\", \"BrandX\", \"BrandY\", \"BrandZ\", \"BrandAA\", \"BrandBB\", \"BrandCC\", \"BrandDD\",\n",
    "        \"BrandEE\", \"BrandFF\", \"BrandGG\", \"BrandHH\", \"BrandII\", \"BrandJJ\", \"BrandKK\", \"BrandLL\", \"BrandMM\", \"BrandNN\",\n",
    "        \"BrandOO\", \"BrandPP\", \"BrandQQ\", \"BrandRR\", \"BrandSS\", \"BrandTT\", \"BrandUU\", \"BrandVV\", \"BrandWW\", \"BrandXX\"\n",
    "    ]\n",
    "\n",
    "    # Category-specific descriptions\n",
    "    descriptions = {\n",
    "        \"Electronics\": [\n",
    "            \"Latest technology with cutting-edge features.\",\n",
    "            \"High performance and sleek design.\",\n",
    "            \"Ideal for tech enthusiasts and professionals.\",\n",
    "            \"Reliable and durable with excellent battery life.\",\n",
    "            \"Compact and lightweight for easy portability.\"\n",
    "        ],\n",
    "        \"Clothing\": [\n",
    "            \"Comfortable and stylish for any occasion.\",\n",
    "            \"Made from high-quality materials for a perfect fit.\",\n",
    "            \"Trendy design that stands out.\",\n",
    "            \"Versatile and easy to pair with different outfits.\",\n",
    "            \"Durable fabric for long-lasting wear.\"\n",
    "        ],\n",
    "        \"Home & Kitchen\": [\n",
    "            \"Essential appliance for modern homes.\",\n",
    "            \"Stylish design to complement your kitchen.\",\n",
    "            \"Energy-efficient and easy to use.\",\n",
    "            \"High performance for all your cooking needs.\",\n",
    "            \"Compact design saves space.\"\n",
    "        ],\n",
    "        \"Books\": [\n",
    "            \"Engaging story that captivates readers.\",\n",
    "            \"Informative and educational content.\",\n",
    "            \"Perfect for readers of all ages.\",\n",
    "            \"Beautifully illustrated with vibrant colors.\",\n",
    "            \"Thought-provoking and inspiring.\"\n",
    "        ],\n",
    "        \"Toys\": [\n",
    "            \"Fun and educational for children.\",\n",
    "            \"Safe and durable materials.\",\n",
    "            \"Encourages creativity and imagination.\",\n",
    "            \"Perfect gift for kids of all ages.\",\n",
    "            \"Bright and colorful design.\"\n",
    "        ],\n",
    "        \"Sports\": [\n",
    "            \"High-performance gear for athletes.\",\n",
    "            \"Durable and lightweight materials.\",\n",
    "            \"Designed for comfort and efficiency.\",\n",
    "            \"Ideal for both beginners and professionals.\",\n",
    "            \"Enhances your performance in sports.\"\n",
    "        ],\n",
    "        \"Health & Beauty\": [\n",
    "            \"Nourishes and revitalizes your skin.\",\n",
    "            \"High-quality ingredients for best results.\",\n",
    "            \"Suitable for all skin types.\",\n",
    "            \"Enhances your natural beauty.\",\n",
    "            \"Gentle and effective formula.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Function to generate product data\n",
    "    def generate_product_data(num_rows=10000):\n",
    "        product_data = []\n",
    "        \n",
    "        for _ in range(num_rows):\n",
    "            category = random.choice(list(subcategories.keys()))\n",
    "            product = {\n",
    "                \"ProductID\": fake.uuid4(),\n",
    "                \"ProductName\": random.choice(product_names[category]),\n",
    "                \"Category\": category,\n",
    "                \"SubCategory\": random.choice(subcategories[category]),\n",
    "                \"Brand\": random.choice(brands),\n",
    "                \"Description\": random.choice(descriptions[category]),\n",
    "                \"Price\": round(random.uniform(5, 2000), 2),\n",
    "                \"Discount\": round(random.uniform(0, 0.5), 2),  # Discount as a fraction\n",
    "                \"StockQuantity\": random.randint(0, 1000),\n",
    "                \"SKU\": fake.bothify(text='???-########'),\n",
    "                \"ProductImageURL\": fake.image_url(),\n",
    "                \"ProductRating\": round(random.uniform(1, 5), 1),\n",
    "                \"NumberOfReviews\": random.randint(0, 5000),\n",
    "                \"SupplierID\": fake.uuid4(),\n",
    "                \"DateAdded\": fake.date_this_decade(),\n",
    "                \"Dimensions\": f\"{random.uniform(1, 100):.2f} x {random.uniform(1, 100):.2f} x {random.uniform(1, 100):.2f}\",\n",
    "                \"Weight\": round(random.uniform(0.1, 50), 2),\n",
    "                \"Color\": fake.color_name(),\n",
    "                \"Material\": random.choice([\"Plastic\", \"Metal\", \"Wood\", \"Glass\", \"Fabric\"]),\n",
    "                \"WarrantyPeriod\": f\"{random.randint(1, 24)} months\",\n",
    "                \"ReturnPolicy\": random.choice([\"30 days\", \"60 days\", \"No returns\"]),\n",
    "                \"ShippingCost\": round(random.uniform(0, 50), 2),\n",
    "                \"ProductTags\": [fake.word() for _ in range(random.randint(1, 5))]\n",
    "            }\n",
    "            product_data.append(product)\n",
    "        \n",
    "        return pd.DataFrame(product_data)\n",
    "\n",
    "    # Generate the product data\n",
    "    product_pdf = generate_product_data(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0747266a-a37c-4939-9935-277210566b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    # Convert the Pandas DataFrame to a PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"ProductID\", StringType(), False),\n",
    "        StructField(\"ProductName\", StringType(), False),\n",
    "        StructField(\"Category\", StringType(), False),\n",
    "        StructField(\"SubCategory\", StringType(), False),\n",
    "        StructField(\"Brand\", StringType(), False),\n",
    "        StructField(\"Description\", StringType(), False),\n",
    "        StructField(\"Price\", FloatType(), False),\n",
    "        StructField(\"Discount\", FloatType(), False),\n",
    "        StructField(\"StockQuantity\", IntegerType(), False),\n",
    "        StructField(\"SKU\", StringType(), False),\n",
    "        StructField(\"ProductImageURL\", StringType(), False),\n",
    "        StructField(\"ProductRating\", FloatType(), False),\n",
    "        StructField(\"NumberOfReviews\", IntegerType(), False),\n",
    "        StructField(\"SupplierID\", StringType(), False),\n",
    "        StructField(\"DateAdded\", DateType(), False),\n",
    "        StructField(\"Dimensions\", StringType(), False),\n",
    "        StructField(\"Weight\", FloatType(), False),\n",
    "        StructField(\"Color\", StringType(), False),\n",
    "        StructField(\"Material\", StringType(), False),\n",
    "        StructField(\"WarrantyPeriod\", StringType(), False),\n",
    "        StructField(\"ReturnPolicy\", StringType(), False),\n",
    "        StructField(\"ShippingCost\", FloatType(), False),\n",
    "        StructField(\"ProductTags\", ArrayType(StringType()), False)\n",
    "    ])\n",
    "\n",
    "    # Create Spark DataFrame & Write to Delta\n",
    "    product_df = spark.createDataFrame(product_pdf, schema)\n",
    "    product_df.write.mode('overwrite').saveAsTable('bronze_product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef3f7abd-7e79-4421-9ed9-8acffed34a4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Genearate the transactions table\n",
    "\n",
    "Schema for the transactions Table:\n",
    "- **TransactionID**: Unique identifier for the transcation\n",
    "- **UserID**: Unique identifier for the user\n",
    "- **ProductID**: Unique identifier for the product\n",
    "- **TransactionDate**: Transcation timestamp\n",
    "- **Quantity**: Number of the items ordered\n",
    "- **UnitPrice**: Unit price for the item ordered\n",
    "- **TotalPrice**: Total amount of the purchase\n",
    "- **PaymentMethod**: The payment method\n",
    "- **ShippingAddress**: The shipping address for the order\n",
    "- **LoyaltyPointsEarned**: The loyalty points earned per purchase (10% of total amount)\n",
    "- **GiftWrap**: yes or no on gift wrap\n",
    "- **SpecialInstructions**: Any other special intructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55b86867-04cf-49be-992f-35c6110a01bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Customizations:\n",
    "- Date Range: Transactions are generated for each day within the specified date range.\n",
    "- Seasonality: Different seasons have different base transaction volumes.\n",
    "- Weekday/Weekend: Weekend transaction volumes are higher than weekdays.\n",
    "- Marketing Campaigns: Specific days can have higher transaction volumes due to marketing campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dee1eeb-59f6-4637-804f-b67ac386ab1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "\n",
    "    # Function to generate transaction data\n",
    "    def generate_transaction_data(user_pdf_, product_pdf_, start_date_, end_date_, campaigns={}):\n",
    "        transaction_data = []\n",
    "        \n",
    "        # Convert date strings to datetime objects\n",
    "        start_date = datetime.strptime(start_date_, \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(end_date_, \"%Y-%m-%d\")\n",
    "        \n",
    "        # Define seasonality factors\n",
    "        seasonality_factors = {\n",
    "            \"winter\": 1.6,\n",
    "            \"spring\": 1.1,\n",
    "            \"summer\": 1.2,\n",
    "            \"autumn\": 1.4\n",
    "        }\n",
    "        \n",
    "        # Iterate over each date in the range\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            # Determine seasonality factor based on month\n",
    "            month = current_date.month\n",
    "            if month in [12, 1]:\n",
    "                seasonality_factor = seasonality_factors[\"winter\"]\n",
    "            elif month in [2, 3, 4, 5]:\n",
    "                seasonality_factor = seasonality_factors[\"spring\"]\n",
    "            elif month in [6, 7, 8]:\n",
    "                seasonality_factor = seasonality_factors[\"summer\"]\n",
    "            else:\n",
    "                seasonality_factor = seasonality_factors[\"autumn\"]\n",
    "            \n",
    "            # Determine weekday/weekend factor\n",
    "            if current_date.weekday() < 5:  # Weekday\n",
    "                day_factor = 1.0\n",
    "            else:  # Weekend\n",
    "                day_factor = 1.3\n",
    "            \n",
    "            # Determine marketing campaign factor\n",
    "            campaign_factor = campaigns.get(current_date.strftime(\"%Y-%m-%d\"), 1.0)\n",
    "            \n",
    "            # Calculate the base number of transactions for the day\n",
    "            base_transactions = int(100 * day_factor * seasonality_factor * campaign_factor)\n",
    "            \n",
    "            # Apply a random multiplier to introduce variability\n",
    "            random_multiplier = random.uniform(0.9, 1.1)  # Adjust the range for desired variability\n",
    "            daily_transactions = int(base_transactions * random_multiplier)\n",
    "            \n",
    "            # Generate transactions for the day\n",
    "            for _ in range(daily_transactions):\n",
    "                user = user_pdf_.sample(1).iloc[0]\n",
    "                product = product_pdf_.sample(1).iloc[0]\n",
    "                quantity = random.randint(1, 5)\n",
    "                transaction = {\n",
    "                    \"TransactionID\": fake.uuid4(),\n",
    "                    \"UserID\": user[\"UserID\"],\n",
    "                    \"ProductID\": product[\"ProductID\"],\n",
    "                    \"TransactionDate\": fake.date_time_between(start_date=current_date, end_date=current_date + timedelta(days=1)),\n",
    "                    \"Quantity\": quantity,\n",
    "                    \"UnitPrice\": product[\"Price\"],\n",
    "                    \"TotalPrice\": round(product[\"Price\"] * quantity, 2),\n",
    "                    \"PaymentMethod\": random.choice([\"Credit Card\", \"Debit Card\", \"PayPal\", \"Bank Transfer\"]),\n",
    "                    \"ShippingAddress\": user[\"Address\"],\n",
    "                    \"LoyaltyPointsEarned\": int(round(product[\"Price\"] * quantity * 0.1)),  # Example: 10% of the total price in loyalty points\n",
    "                    \"GiftWrap\": random.choice([\"yes\", \"no\"]),\n",
    "                    \"SpecialInstructions\": fake.sentence() if random.choice([True, False]) else \"\"\n",
    "                }\n",
    "                transaction_data.append(transaction)\n",
    "            \n",
    "            # Move to the next day\n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        return pd.DataFrame(transaction_data)\n",
    "\n",
    "    # Generate the transaction data\n",
    "    # Set the current date\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Calculate the start date (30 days from now)\n",
    "    start_date = (current_date - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Set the end date to today\n",
    "    end_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Define the campaigns with the last campaign date being 8 days before today\n",
    "    campaigns = {\n",
    "        # \"2023-07-15\": 2.0 ,  # Example campaign day with doubled sales\n",
    "        # \"2023-11-23\": 1.5 ,  # Another example campaign day with 50% higher sales\n",
    "        # \"2024-03-10\": 2.0 , # Example campaign day with doubled sales\n",
    "        (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\"): 2.0  # Last campaign date is today - 1 days\n",
    "    }\n",
    "\n",
    "    # Generate the transaction data\n",
    "    transaction_pdf = generate_transaction_data(user_pdf, product_pdf, start_date, end_date, campaigns)\n",
    "\n",
    "    # Convert the Pandas DataFrame to a PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"TransactionID\", StringType(), False),\n",
    "        StructField(\"UserID\", StringType(), False),\n",
    "        StructField(\"ProductID\", StringType(), False),\n",
    "        StructField(\"TransactionDate\", TimestampType(), False),\n",
    "        StructField(\"Quantity\", IntegerType(), False),\n",
    "        StructField(\"UnitPrice\", FloatType(), False),\n",
    "        StructField(\"TotalPrice\", FloatType(), False),\n",
    "        StructField(\"PaymentMethod\", StringType(), False),\n",
    "        StructField(\"ShippingAddress\", StringType(), False),\n",
    "        StructField(\"LoyaltyPointsEarned\", IntegerType(), False),\n",
    "        StructField(\"GiftWrap\", StringType(), False),\n",
    "        StructField(\"SpecialInstructions\", StringType(), False)\n",
    "    ])\n",
    "\n",
    "    # Create Spark DataFrame and Write to Delta table\n",
    "    transaction_df = spark.createDataFrame(transaction_pdf, schema)\n",
    "    transaction_df.write.mode('overwrite').saveAsTable('bronze_transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48512b11-7f10-4c8d-b3b0-fd61c502f17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "user_df = spark.read.table(\"bronze_user\")\n",
    "product_df = spark.read.table(\"bronze_product\")\n",
    "transaction_df = spark.read.table(\"bronze_transaction\")\n",
    "\n",
    "# Join the DataFrames\n",
    "joined_df = (\n",
    "    transaction_df\n",
    "    .join(user_df, on=\"UserID\", how=\"left\")\n",
    "    .join(product_df, on=\"ProductID\", how=\"left\")\n",
    ")\n",
    "\n",
    "def inject_issues(df_in, campaign_start_dates):\n",
    "    # Ensure TransactionDate is in the correct format and create 'TempDate'\n",
    "    df = df_in.withColumn('TempDate', F.to_date(F.col('TransactionDate')))\n",
    "    \n",
    "    # Add the Campaign_flag column, initially set to False\n",
    "    df = df.withColumn('Campaign_flag', F.lit(False))\n",
    "    \n",
    "    # Steady nulls around 10-15% in specified columns (e.g., ProductTags, ShippingAddress, Wishlist, GiftWrap)\n",
    "    steady_null_columns = ['ProductTags', 'ShippingAddress', 'Wishlist', 'GiftWrap']\n",
    "    for column in steady_null_columns:\n",
    "        df = df.withColumn(column, F.when(F.rand() < random.uniform(0.1, 0.15), None).otherwise(F.col(column)))\n",
    "    \n",
    "    # Steady nulls around 10% in PreferredPaymentMethod\n",
    "    df = df.withColumn('PreferredPaymentMethod', F.when(F.rand() < random.uniform(0.05, 0.09), None).otherwise(F.col('PreferredPaymentMethod')))\n",
    "    \n",
    "    # 60% zeros in Discount distributed evenly over time\n",
    "    df = df.withColumn('Discount', F.when(F.rand() < 0.6, F.lit(0)).otherwise(F.col('Discount')))\n",
    "    \n",
    "    # 10% zeros in ProductRating distributed evenly over time\n",
    "    df = df.withColumn('ProductRating', F.when(F.rand() < 0.1, F.lit(0)).otherwise(F.col('ProductRating')))\n",
    "    \n",
    "    # Iterate through each campaign start date and apply specific rules\n",
    "    for start_date in campaign_start_dates:\n",
    "        start_date_lit = F.lit(start_date)\n",
    "        campaign_mask = (F.col('TempDate') >= start_date_lit) & (F.col('TempDate') < F.date_add(start_date_lit, 10))\n",
    "        \n",
    "        # Set NumberOfReviews to 0 during the campaign\n",
    "        df = df.withColumn('NumberOfReviews', F.when(campaign_mask, F.lit(0)).otherwise(F.col('NumberOfReviews')))\n",
    "        \n",
    "        # Set PreferredPaymentMethod to null for 48% during the campaign\n",
    "        df = df.withColumn('PreferredPaymentMethod', F.when(campaign_mask & (F.rand() < 0.48), None).otherwise(F.col('PreferredPaymentMethod')))\n",
    "        \n",
    "        # Set PaymentMethod to 'Apple Pay' for 80% during the campaign\n",
    "        df = df.withColumn('PaymentMethod', F.when(campaign_mask & (F.rand() < 0.8), 'Apple Pay').otherwise(F.col('PaymentMethod')))\n",
    "        \n",
    "        # Dramatic change in Quantity and TotalPrice for 10 days after each campaign start date\n",
    "        df = df.withColumn('Quantity', F.when(campaign_mask, F.col('Quantity') * 1.5).otherwise(F.col('Quantity')))\n",
    "        df = df.withColumn('TotalPrice', F.when(campaign_mask, F.col('Quantity') * F.col('UnitPrice')).otherwise(F.col('TotalPrice')))\n",
    "        \n",
    "        # Set the Campaign_flag for these dates and return\n",
    "        return df.withColumn('Campaign_flag', F.when(campaign_mask, F.lit(True)).otherwise(F.col('Campaign_flag')))\n",
    "    \n",
    "    # After 20 days: Apply changes to WarrantyPeriod and ReturnPolicy\n",
    "    last_20_days_mask = (F.col('TempDate').substr(0, 4) == \"2024\") & (F.col('TempDate').substr(6, 2) >= \"05\")\n",
    "    \n",
    "    # Overwrite over 50% of WarrantyPeriod to '15 days'\n",
    "    df = df.withColumn('WarrantyPeriod', F.when(last_20_days_mask & (F.rand() < 0.7), '15 days').otherwise(F.col('WarrantyPeriod')))\n",
    "    \n",
    "    # Overwrite over 50% of ReturnPolicy to 'no returns'\n",
    "    df = df.withColumn('ReturnPolicy', F.when(last_20_days_mask & (F.rand() < 0.7), 'no returns').otherwise(F.col('ReturnPolicy')))\n",
    "    \n",
    "    # Drop the temporary date column\n",
    "    df = df.drop('TempDate')\n",
    "    \n",
    "    return df\n",
    "\n",
    "if not data_exists:\n",
    "    # Define current date\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Generate campaign start dates as a list\n",
    "    campaign_start_dates = [(current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "    # Alternatively, you can use predefined campaign dates (uncomment if needed)\n",
    "    # campaign_start_dates = [\"2023-07-15\", \"2023-11-23\", \"2024-03-10\", (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
    "\n",
    "    # Apply the inject_issues_spark function to the Spark DataFrame\n",
    "    joined_with_issues_df = inject_issues(joined_df, campaign_start_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dd71a43-aedf-4ab9-ae91-6e552e4218af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    # Define the schema\n",
    "    schema = StructType([\n",
    "        StructField('TransactionID', StringType(), True),\n",
    "        StructField('UserID', StringType(), True),\n",
    "        StructField('ProductID', StringType(), True),\n",
    "        StructField('TransactionDate', TimestampType(), True),\n",
    "        StructField('Quantity', DoubleType(), True),\n",
    "        StructField('UnitPrice', DoubleType(), True),\n",
    "        StructField('TotalPrice', DoubleType(), True),\n",
    "        StructField('PaymentMethod', StringType(), True),\n",
    "        StructField('ShippingAddress', StringType(), True),\n",
    "        StructField('LoyaltyPointsEarned', IntegerType(), True),\n",
    "        StructField('GiftWrap', StringType(), True),\n",
    "        StructField('SpecialInstructions', StringType(), True),\n",
    "        StructField('Username', StringType(), True),\n",
    "        StructField('Email', StringType(), True),\n",
    "        StructField('PasswordHash', StringType(), True),\n",
    "        StructField('FullName', StringType(), True),\n",
    "        StructField('DateOfBirth', DateType(), True),\n",
    "        StructField('Gender', StringType(), True),\n",
    "        StructField('PhoneNumber', StringType(), True),\n",
    "        StructField('Address', StringType(), True),\n",
    "        StructField('City', StringType(), True),\n",
    "        StructField('State', StringType(), True),\n",
    "        StructField('Country', StringType(), True),\n",
    "        StructField('PostalCode', StringType(), True),\n",
    "        StructField('RegistrationDate', DateType(), True),\n",
    "        StructField('LastLoginDate', TimestampType(), True),\n",
    "        StructField('AccountStatus', StringType(), True),\n",
    "        StructField('UserRole', StringType(), True),\n",
    "        StructField('PreferredPaymentMethod', StringType(), True),\n",
    "        StructField('TotalPurchaseAmount', DoubleType(), True),\n",
    "        StructField('NewsletterSubscription', BooleanType(), True),\n",
    "        StructField('Wishlist', ArrayType(StringType()), True),\n",
    "        StructField('CartItems', ArrayType(StringType()), True),\n",
    "        StructField('ProductName', StringType(), True),\n",
    "        StructField('Category', StringType(), True),\n",
    "        StructField('SubCategory', StringType(), True),\n",
    "        StructField('Brand', StringType(), True),\n",
    "        StructField('Description', StringType(), True),\n",
    "        StructField('Price', DoubleType(), True),\n",
    "        StructField('Discount', DoubleType(), True),\n",
    "        StructField('StockQuantity', IntegerType(), True),\n",
    "        StructField('SKU', StringType(), True),\n",
    "        StructField('ProductImageURL', StringType(), True),\n",
    "        StructField('ProductRating', DoubleType(), True),\n",
    "        StructField('NumberOfReviews', IntegerType(), True),\n",
    "        StructField('SupplierID', StringType(), True),\n",
    "        StructField('DateAdded', DateType(), True),\n",
    "        StructField('Dimensions', StringType(), True),\n",
    "        StructField('Weight', DoubleType(), True),\n",
    "        StructField('Color', StringType(), True),\n",
    "        StructField('Material', StringType(), True),\n",
    "        StructField('WarrantyPeriod', StringType(), True),\n",
    "        StructField('ReturnPolicy', StringType(), True),\n",
    "        StructField('ShippingCost', DoubleType(), True),\n",
    "        StructField('ProductTags', ArrayType(StringType()), True),\n",
    "        StructField('Campaign_flag', BooleanType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Make sure to convert dates like 'DateOfBirth', 'RegistrationDate', and 'DateAdded' to appropriate formats\n",
    "    joined_with_issues_df = joined_with_issues_df \\\n",
    "        .withColumn('DateOfBirth', F.col('DateOfBirth').cast(DateType())) \\\n",
    "        .withColumn('RegistrationDate', F.col('RegistrationDate').cast(DateType())) \\\n",
    "        .withColumn('DateAdded', F.col('DateAdded').cast(DateType()))\n",
    "\n",
    "    # Ensure Wishlist, CartItems, and ProductTags are either arrays or null and Write to Delta as \"Silver transaction\" table\n",
    "    joined_with_issues_df = joined_with_issues_df \\\n",
    "        .withColumn('Wishlist', F.when(F.col('Wishlist').isNull(), None).otherwise(F.col('Wishlist'))) \\\n",
    "        .withColumn('CartItems', F.when(F.col('CartItems').isNull(), None).otherwise(F.col('CartItems'))) \\\n",
    "        .withColumn('ProductTags', F.when(F.col('ProductTags').isNull(), None).otherwise(F.col('ProductTags')))\n",
    "        \n",
    "    joined_with_issues_df.write.option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable('silver_transaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a2274e9-9226-4bfb-a170-b0f208dd9c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Gold Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eea0a394-74d7-4e64-a3b6-f96132738270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "\n",
    "    from pyspark.sql import Window\n",
    "\n",
    "    # Create a temporary column for Month from silver table\n",
    "    tmp_df = spark.read.table(\"silver_transaction\").withColumn(\"Month\", F.date_format(F.col(\"TransactionDate\"), \"yyyy-MM\"))\n",
    "\n",
    "    ## Monthly Sales Summary by Category\n",
    "    tmp_df \\\n",
    "        .groupBy(\"Month\", \"Category\") \\\n",
    "        .agg(\n",
    "            F.sum(\"TotalPrice\").alias(\"TotalSales\"),\n",
    "            F.sum(\"Quantity\").alias(\"TotalQuantitySold\")\n",
    "        ) \\\n",
    "        .orderBy(\"Month\", \"Category\") \\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable(f'gold_monthly_sales')\n",
    "\n",
    "    ## Top 10 Products by Total Sales by Month\n",
    "    tmp_df \\\n",
    "        .groupBy(\"Month\", \"ProductID\", \"ProductName\") \\\n",
    "        .agg(\n",
    "            F.sum(\"TotalPrice\").alias(\"TotalSales\")\n",
    "        ) \\\n",
    "        .withColumn(\"Rank\", F.row_number().over(Window.partitionBy(\"Month\").orderBy(F.desc(\"TotalSales\")))) \\\n",
    "        .filter(F.col(\"Rank\") <= 10) \\\n",
    "        .orderBy(\"Month\", \"Rank\")\\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable('gold_top_products')\n",
    "\n",
    "    ## User Purchase Behavior by Month\n",
    "    tmp_df \\\n",
    "        .groupBy(\"Month\", \"UserID\", \"Username\") \\\n",
    "        .agg(\n",
    "            F.sum(\"TotalPrice\").alias(\"TotalPurchaseAmount\"),\n",
    "            F.avg(\"TotalPrice\").alias(\"AveragePurchaseAmount\"),\n",
    "            F.count(\"TransactionID\").alias(\"TotalTransactions\")\n",
    "        ) \\\n",
    "        .orderBy(\"Month\", \"UserID\") \\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").mode('overwrite').saveAsTable('gold_user_purchase')\n",
    "\n",
    "    ## Gold Payment methods\n",
    "    spark.read.table(\"silver_transaction\") \\\n",
    "        .select(\n",
    "            \"TransactionID\", \n",
    "            \"UserID\", \n",
    "            \"PaymentMethod\", \n",
    "            \"PreferredPaymentMethod\", \n",
    "            \"Price\", \n",
    "            \"Quantity\"\n",
    "        ) \\\n",
    "        .orderBy(\"TransactionID\") \\\n",
    "        .write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable('gold_payment_method')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08_DataGeneration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}